{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c6bb93",
   "metadata": {},
   "source": [
    "Evaluation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697601ed",
   "metadata": {},
   "source": [
    "For this homework, we will use the same dataset we generated in the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c58a00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading documents and ground truth data for search evaluation\n",
    "# This script fetches the documents and ground truth data from a specified URL\n",
    "# and prepares them for further analysis.\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
    "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
    "documents = requests.get(docs_url).json()\n",
    "\n",
    "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c664b586",
   "metadata": {},
   "source": [
    "Here, documents contains the documents from the FAQ database with unique IDs, and ground_truth contains generated question-answer pairs.\n",
    "\n",
    "Also, we will need the code for evaluating retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8cbc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below is used to evaluate the retrieval performance of a search function.\n",
    "# It calculates the hit rate and mean reciprocal rank (MRR) based on the relevance of\n",
    "# the search results to the ground truth data.\n",
    "\n",
    "# Use the tqdm library to show a progress bar while evaluating each query.\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Calculate the hit rate: proportion of queries where the correct document is found in the results\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "# Calculate the mean reciprocal rank (MRR): average of reciprocal ranks of the first relevant result\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "# Evaluate a search function using ground truth data\n",
    "# Returns a dictionary with hit_rate and mrr\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        # Check if each result matches the ground truth document id\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e45a030",
   "metadata": {},
   "source": [
    "### Q1. Minsearch text\n",
    "\n",
    "Now let's evaluate our usual minsearch approach, but tweak the parameters. Let's use the following boosting params: \n",
    "`boost = {'question': 1.5, 'section': 0.1}`\n",
    "\n",
    "What's the hitrate for this approach?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a33f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x7e801a7b36e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "# Create a minsearch index with specified text and keyword fields\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\", \"id\"]\n",
    ")\n",
    "# Fit the index to the documents (build the search index)\n",
    "index.fit(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96ff562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs a search query on the minsearch index for course-related questions.\n",
    "# It takes a query string and a course identifier as parameters.\n",
    "#\n",
    "# The search query uses the minsearch index to find documents that match the query string,\n",
    "# with a higher weight given to the \"question\" field.\n",
    "# \n",
    "# It filters the results to only include documents that match the specified course.\n",
    "# The search results are limited to the top 5 matches based on relevance.\n",
    "def minsearch_search(query, course):\n",
    "    boost = {'question': 1.5, 'section': 0.1}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': course},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc22f2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f896e99a95244839c2eb62a90f21e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.848714069591528, 'mrr': 0.7288235717887772}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question'], q['course']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b7e9e",
   "metadata": {},
   "source": [
    "Answer: hit_rate 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b6ce1",
   "metadata": {},
   "source": [
    "Embeddings\n",
    "\n",
    "The latest version of minsearch also supports vector search. We will use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6fb251",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U minsearch qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d90d5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import VectorSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b70e49",
   "metadata": {},
   "source": [
    "We will also use TF-IDF and Singular Value Decomposition to create embeddings from texts. \n",
    "You can refer to our \"Create Your Own Search Engine\" workshop if you want to know more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5283d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e93d2d5",
   "metadata": {},
   "source": [
    "Let's create embeddings for the \"question\" field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc3a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code creates a pipeline that combines TF-IDF vectorization and Truncated SVD for dimensionality reduction.\n",
    "# It processes the 'question' field from the documents to generate a matrix of features.\n",
    "\n",
    "# Prepare a list of questions from the documents for embedding\n",
    "texts = []\n",
    "for doc in documents:\n",
    "    t = doc['question']\n",
    "    texts.append(t)\n",
    "\n",
    "# Create a pipeline that vectorizes text using TF-IDF and reduces dimensionality with SVD\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),                  # Ignore terms that appear in fewer than 3 documents\n",
    "    TruncatedSVD(n_components=128, random_state=1)  # Reduce to 128 dimensions\n",
    ")\n",
    "\n",
    "# Fit the pipeline to the questions and transform them into embeddings\n",
    "X = pipeline.fit_transform(texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d39aa2",
   "metadata": {},
   "source": [
    "### Q2. Vector search for question\n",
    "\n",
    "Now let's index these embeddings with minsearch:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21db4da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector search index using minsearch, specifying 'course' as a keyword field for filtering\n",
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "\n",
    "# Fit the vector index with the embeddings (X) and the original documents\n",
    "vindex.fit(X, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs a search query on the vector index for course-related questions.\n",
    "def vector_search(query, course):\n",
    "    X = pipeline.transform([query])         # Convert query to vector\n",
    "    results = vindex.search(                # Search using vector index\n",
    "        X[0],                               # x[0] is the vector itself\n",
    "        filter_dict={'course': course},     # Same filtering as before\n",
    "        num_results=5\n",
    "    )\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3ae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ground_truth, lambda q: vector_search(q['question'], q['course']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295e474",
   "metadata": {},
   "source": [
    "Answer: MRR fo rthis seach method is 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c591b29",
   "metadata": {},
   "source": [
    "### Q3. Vector search for question and answer\n",
    "\n",
    "We only used question in Q2. We can use both question and answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e30fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold the combined question and text for each document\n",
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    # Concatenate the 'question' and 'text' fields for each document\n",
    "    t = doc['question'] + ' ' + doc['text']\n",
    "    texts.append(t)\n",
    "\n",
    "# Create a pipeline that vectorizes text using TF-IDF and reduces dimensionality with SVD\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),                  # Ignore terms that appear in fewer than 3 documents\n",
    "    TruncatedSVD(n_components=128, random_state=1)  # Reduce to 128 dimensions\n",
    ")\n",
    "\n",
    "# Fit the pipeline to the combined texts and transform them into embeddings\n",
    "X = pipeline.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1436f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3989e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search_qa(query, course):\n",
    "    x = pipeline.transform([query])\n",
    "    results = vindex.search(\n",
    "        x[0],\n",
    "        filter_dict={'course': course},\n",
    "        num_results=5\n",
    "    )\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8486ef74",
   "metadata": {},
   "source": [
    "Using the same pipeline `(min_df=3 for TF-IDF vectorizer and n_components=128 for SVD)`, evaluate the performance of this approach\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0076624",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ground_truth, lambda q: vector_search(q['question'], q['course']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bb8de6",
   "metadata": {},
   "source": [
    "Answer: Hit Rate for this approach is 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4fd759",
   "metadata": {},
   "source": [
    "### Q4. Qdrant\n",
    "Now let's evaluate the following settings in Qdrant:\n",
    "- `text = doc['question'] + ' ' + doc['text']`\n",
    "- `model_handle = \"jinaai/jina-embeddings-v2-small-en\"`\n",
    "- `limit = 5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b9d5b2-e87b-45be-b9dc-2c0625e5104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"qdrant-client[fastembed]>=1.14.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf641e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from fastembed import TextEmbedding\n",
    "from typing import List\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c103ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "415f9ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"jinaai/jina-embeddings-v2-small-en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daf242ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextEmbedding(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc76055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the collection name\n",
    "# collection_name = \"llm-zoomcamp-homework3\"\n",
    "if not client.collection_exists('llm-zoomcamp-homework3'):\n",
    "# Create the collection with specified vector parameters\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=client.get_embedding_size(model_name),  # Dimensionality of the vectors\n",
    "            distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fde497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare texts and metadata\n",
    "texts = []\n",
    "payloads = []\n",
    "for doc in documents:\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    texts.append(text)\n",
    "    payloads.append({\n",
    "        \"text\": doc['text'],\n",
    "        \"section\": doc['section'],\n",
    "        \"course\": doc['course'],\n",
    "        \"id\": doc['id']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c487f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the batch size for uploading vectors to Qdrant\n",
    "batch_size = 16\n",
    "\n",
    "# Iterate over the texts and payloads in batches\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    batch_texts = texts[i:i + batch_size]           # Get a batch of texts\n",
    "    batch_payloads = payloads[i:i + batch_size]     # Get the corresponding payloads\n",
    "    batch_vectors = list(model.embed(batch_texts))  # Generate embeddings for the batch\n",
    "\n",
    "    points = []\n",
    "    # Create Qdrant PointStructs for each vector in the batch\n",
    "    for j, vector in enumerate(batch_vectors):\n",
    "        points.append(models.PointStruct(\n",
    "            id=str(uuid4()),                       # Generate a unique ID for each point\n",
    "            vector=vector,                         # The embedding vector\n",
    "            payload=batch_payloads[j]              # Associated metadata\n",
    "        ))\n",
    "\n",
    "    # Upload the batch of points to the Qdrant collection\n",
    "    client.upsert(collection_name=collection_name, points=points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af617039-bbf5-43fb-abd8-a291b06a47c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qdrant_search_fastembed(question, course, limit=5):\n",
    "    # Generate the embedding vector for the input question using the fastembed model\n",
    "    query_vector = list(model.embed([question]))[0]\n",
    "\n",
    "    # Perform a vector search in the Qdrant collection, filtering by course\n",
    "    hits = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_vector,\n",
    "        limit=limit,\n",
    "        query_filter={\n",
    "            \"must\": [{\"key\": \"course\", \"match\": {\"value\": course}}]\n",
    "        }\n",
    "    )\n",
    "    # Return the payload (metadata) of each search result\n",
    "    return [hit.payload for hit in hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6139dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ground_truth, lambda q: qdrant_search_fastembed(q['question'], q['course']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6383ad6",
   "metadata": {},
   "source": [
    "Answer: MRR is 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0ef6a4",
   "metadata": {},
   "source": [
    "### Q5. Cosine simiarity\n",
    "In the second part of the module, we looked at evaluating the entire RAG approach. In particular, we looked at comparing the answer generated by our system with the actual answer from the FAQ.\n",
    "\n",
    "One of the ways of doing it is using the cosine similarity. Let's see how to calculate it.\n",
    "\n",
    "Cosine similarity is a dot product between two normalized vectors. In geometrical sense, it's the cosine of the angle between the vectors. Look up \"cosine similarity geometry\" if you want to learn more about it.\n",
    "\n",
    "For us, it means that we need two things:\n",
    "\n",
    "First, we normalize each of the vectors\n",
    "Then, compute the dot product\n",
    "So, we get this:\n",
    "\n",
    "```\n",
    "def cosine(u, v):\n",
    "    u = normalize(u)\n",
    "    v = normalize(v)\n",
    "    return u.dot(v)\n",
    "```\n",
    "\n",
    "For normalization, we first compute the vector norm (its length), and then divide the vector by it:\n",
    "\n",
    "```\n",
    "def normalize(u):\n",
    "    norm = np.sqrt(u.dot(u))\n",
    "    return u / norm\n",
    "```\n",
    "\n",
    "(where `np` is import `numpy as np`)\n",
    "\n",
    "Or we can simplify it:\n",
    "```\n",
    "def cosine(u, v):\n",
    "    u_norm = np.sqrt(u.dot(u))\n",
    "    v_norm = np.sqrt(v.dot(v))\n",
    "    return u.dot(v) / (u_norm * v_norm)\n",
    "```\n",
    "\n",
    "Now let's use this function to compute the A->Q->A cosine similarity.\n",
    "\n",
    "We will use the results from our gpt-4o-mini evaluations:\n",
    "\n",
    "```\n",
    "results_url = url_prefix + 'rag_evaluation/data/results-gpt4o-mini.csv'\n",
    "df_results = pd.read_csv(results_url)\n",
    "```\n",
    "When creating embeddings, we will use a simple way - the same we used in the Embeddings section:\n",
    "```\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "```\n",
    "Let's fit the vectorizer on all the text data we have:\n",
    "`pipeline.fit(df_results.answer_llm + ' ' + df_results.answer_orig + ' ' + df_results.question)`\n",
    "\n",
    "Now use the `transform` method of the pipeline to create the embeddings and calculate the cosine similarity between each pair.\n",
    "\n",
    "- For each answer pair, compute\n",
    "    - `v_llm` for the answer from the LLM\n",
    "    - `v_orig` for the original answer\n",
    "    - then compute the cosine between them\n",
    "- At the end, take the average\n",
    "\n",
    "What's the average cosine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e9ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    u_norm = np.sqrt(u.dot(u))\n",
    "    v_norm = np.sqrt(v.dot(v))\n",
    "    return u.dot(v) / (u_norm * v_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "116867a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_url = url_prefix + 'rag_evaluation/data/results-gpt4o-mini.csv'\n",
    "df_results = pd.read_csv(results_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af29f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718c7c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8838806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer(min_df=3)),\n",
       "                (&#x27;truncatedsvd&#x27;,\n",
       "                 TruncatedSVD(n_components=128, random_state=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer(min_df=3)),\n",
       "                (&#x27;truncatedsvd&#x27;,\n",
       "                 TruncatedSVD(n_components=128, random_state=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(min_df=3)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TruncatedSVD<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.decomposition.TruncatedSVD.html\">?<span>Documentation for TruncatedSVD</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TruncatedSVD(n_components=128, random_state=1)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(min_df=3)),\n",
       "                ('truncatedsvd',\n",
       "                 TruncatedSVD(n_components=128, random_state=1))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(df_results.answer_llm + ' ' + df_results.answer_orig + ' ' + df_results.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03210111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings\n",
    "X_llm = pipeline.transform(df_results['answer_llm'])\n",
    "X_orig = pipeline.transform(df_results['answer_orig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05a7d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30e6f6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity: 0.84\n"
     ]
    }
   ],
   "source": [
    "cosines = [cosine(u, v) for u, v in zip(X_llm, X_orig)]\n",
    "print(\"Average cosine similarity:\", round(np.mean(cosines), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d3134",
   "metadata": {},
   "source": [
    "Answer: average cosine similarity: 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad58cd",
   "metadata": {},
   "source": [
    "### Q6. Rouge\n",
    "And alternative way to see how two texts are similar is ROUGE.\n",
    "\n",
    "This is a set of metrics that compares two answers based on the overlap of n-grams, word sequences, and word pairs.\n",
    "\n",
    "It can give a more nuanced view of text similarity than just cosine similarity alone.\n",
    "\n",
    "We don't need to implement it ourselves, there's a python package for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1266caf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in /home/dmelnitsyn/anaconda3/lib/python3.12/site-packages (from rouge) (1.16.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df538d",
   "metadata": {},
   "source": [
    "(The latest version at the moment of writing is 1.0.1)\n",
    "\n",
    "Let's compute the ROUGE score between the answers at the index 10 of our dataframe (doc_id=5170565b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d915f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.45454545454545453,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.45454544954545456},\n",
       " 'rouge-2': {'r': 0.21621621621621623,\n",
       "  'p': 0.21621621621621623,\n",
       "  'f': 0.21621621121621637},\n",
       " 'rouge-l': {'r': 0.3939393939393939,\n",
       "  'p': 0.3939393939393939,\n",
       "  'f': 0.393939388939394}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "# Initialize the Rouge scorer\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "# Select the 10th row from the results dataframe\n",
    "sample_result = df_results.iloc[10]\n",
    "\n",
    "# Compute ROUGE scores between the LLM answer and the original answer for the sample\n",
    "scores = rouge_scorer.get_scores(sample_result.answer_llm, sample_result.answer_orig)[0]\n",
    "\n",
    "# Display the ROUGE scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf82aef",
   "metadata": {},
   "source": [
    "There are three scores: `rouge-1`, `rouge-2` and `rouge-l`, and precision, recall and F1 score for each.\n",
    "\n",
    "- `rouge-1` - the overlap of unigrams,\n",
    "- `rouge-2` - bigrams,\n",
    "- `rouge-l` - the longest common subsequence\n",
    "\n",
    "For the 10th document, Rouge-1 F1 score is 0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5903b3c5",
   "metadata": {},
   "source": [
    "Let's compute it for the pairs in the entire dataframe. What's the average Rouge-1 F1?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c725d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store Rouge-1 F1 scores for each answer pair\n",
    "rouge_1_f1 = []\n",
    "\n",
    "# Iterate over each row in the results dataframe\n",
    "for _, row in df_results.iterrows():\n",
    "    # Compute ROUGE scores between the LLM answer and the original answer\n",
    "    scores = rouge_scorer.get_scores(row.answer_llm, row.answer_orig)[0]\n",
    "    # Append the Rouge-1 F1 score to the list\n",
    "    rouge_1_f1.append(scores['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "827a632c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3516946452113944"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rouge_1_f1 = sum(rouge_1_f1) / len(rouge_1_f1)\n",
    "avg_rouge_1_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5400a7d7",
   "metadata": {},
   "source": [
    "Answer: the average Rouge-1 F1 is 0.35"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
